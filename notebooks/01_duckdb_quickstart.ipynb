{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DuckDB Quickstart Guide\n",
    "\n",
    "This notebook demonstrates how to use DuckDB for fast analytical queries in the ML Practice environment.\n",
    "\n",
    "## What is DuckDB?\n",
    "\n",
    "DuckDB is an in-process SQL OLAP database management system designed for analytical workloads. Think of it as \"SQLite for analytics\" - it's:\n",
    "- **Fast**: Optimized for analytical queries\n",
    "- **Embedded**: Runs in-process, no separate server needed\n",
    "- **Versatile**: Works with CSV, Parquet, JSON, and Pandas DataFrames\n",
    "- **SQL**: Full SQL support with window functions, CTEs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "print(f\"DuckDB version: {duckdb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a DuckDB Connection\n",
    "\n",
    "DuckDB can work with:\n",
    "- In-memory databases (fast, but data is lost when connection closes)\n",
    "- File-based databases (persisted to disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: In-memory database (fast, temporary)\n",
    "con_memory = duckdb.connect(':memory:')\n",
    "\n",
    "# Option 2: File-based database (persistent)\n",
    "db_path = '/home/jovyan/work/duckdb/ml_practice.db'\n",
    "os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "con = duckdb.connect(db_path)\n",
    "\n",
    "print(f\"Connected to DuckDB at: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Sample Data\n",
    "\n",
    "Let's create sample ML experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample ML experiment data\n",
    "np.random.seed(42)\n",
    "\n",
    "n_experiments = 1000\n",
    "models = ['RandomForest', 'XGBoost', 'LightGBM', 'NeuralNet', 'LogisticRegression']\n",
    "datasets = ['Iris', 'MNIST', 'CIFAR10', 'Titanic', 'Housing']\n",
    "\n",
    "df_experiments = pd.DataFrame({\n",
    "    'experiment_id': range(1, n_experiments + 1),\n",
    "    'model_type': np.random.choice(models, n_experiments),\n",
    "    'dataset': np.random.choice(datasets, n_experiments),\n",
    "    'accuracy': np.random.uniform(0.7, 0.99, n_experiments),\n",
    "    'precision': np.random.uniform(0.6, 0.98, n_experiments),\n",
    "    'recall': np.random.uniform(0.65, 0.97, n_experiments),\n",
    "    'training_time': np.random.uniform(10, 3600, n_experiments),\n",
    "    'n_estimators': np.random.choice([50, 100, 200, 500], n_experiments),\n",
    "    'learning_rate': np.random.choice([0.01, 0.05, 0.1, 0.3], n_experiments),\n",
    "    'timestamp': [datetime.now() - timedelta(days=np.random.randint(0, 365)) for _ in range(n_experiments)]\n",
    "})\n",
    "\n",
    "df_experiments['f1_score'] = 2 * (df_experiments['precision'] * df_experiments['recall']) / \\\n",
    "                             (df_experiments['precision'] + df_experiments['recall'])\n",
    "\n",
    "print(f\"Created {len(df_experiments)} experiment records\")\n",
    "df_experiments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Querying Pandas DataFrames with DuckDB\n",
    "\n",
    "DuckDB can directly query Pandas DataFrames using SQL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the DataFrame directly (no need to load it into DuckDB first!)\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        model_type,\n",
    "        COUNT(*) as num_experiments,\n",
    "        AVG(accuracy) as avg_accuracy,\n",
    "        AVG(training_time) as avg_training_time_sec\n",
    "    FROM df_experiments\n",
    "    GROUP BY model_type\n",
    "    ORDER BY avg_accuracy DESC\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Persistent Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table from the DataFrame\n",
    "con.execute(\"DROP TABLE IF EXISTS ml_experiments\")\n",
    "con.execute(\"CREATE TABLE ml_experiments AS SELECT * FROM df_experiments\")\n",
    "\n",
    "# Verify table creation\n",
    "tables = con.execute(\"SHOW TABLES\").df()\n",
    "print(\"Tables in database:\")\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced SQL Queries\n",
    "\n",
    "### Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top 3 experiments per model type\n",
    "top_experiments = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT \n",
    "            experiment_id,\n",
    "            model_type,\n",
    "            dataset,\n",
    "            accuracy,\n",
    "            f1_score,\n",
    "            ROW_NUMBER() OVER (PARTITION BY model_type ORDER BY accuracy DESC) as rank\n",
    "        FROM ml_experiments\n",
    "    ) ranked\n",
    "    WHERE rank <= 3\n",
    "    ORDER BY model_type, rank\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Top 3 experiments per model type:\")\n",
    "top_experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations with HAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find dataset-model combinations with high average accuracy\n",
    "high_performers = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        dataset,\n",
    "        model_type,\n",
    "        COUNT(*) as experiments,\n",
    "        ROUND(AVG(accuracy), 4) as avg_accuracy,\n",
    "        ROUND(MIN(accuracy), 4) as min_accuracy,\n",
    "        ROUND(MAX(accuracy), 4) as max_accuracy,\n",
    "        ROUND(STDDEV(accuracy), 4) as std_accuracy\n",
    "    FROM ml_experiments\n",
    "    GROUP BY dataset, model_type\n",
    "    HAVING AVG(accuracy) > 0.85\n",
    "    ORDER BY avg_accuracy DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"High-performing dataset-model combinations (avg accuracy > 0.85):\")\n",
    "high_performers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Working with CSV Files\n",
    "\n",
    "DuckDB can read CSV files directly without loading them into memory first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrame to CSV\n",
    "csv_path = '/home/jovyan/work/data/experiments.csv'\n",
    "os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "df_experiments.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Exported data to: {csv_path}\")\n",
    "\n",
    "# Query CSV directly (no need to load into memory!)\n",
    "csv_query = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        model_type,\n",
    "        COUNT(*) as count\n",
    "    FROM read_csv_auto('/home/jovyan/work/data/experiments.csv')\n",
    "    GROUP BY model_type\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nQuery results from CSV:\")\n",
    "csv_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exporting Results to Parquet\n",
    "\n",
    "Parquet is a columnar storage format that's highly efficient for analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export query results to Parquet\n",
    "parquet_path = '/home/jovyan/work/data/high_performers.parquet'\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "    COPY (\n",
    "        SELECT \n",
    "            dataset,\n",
    "            model_type,\n",
    "            AVG(accuracy) as avg_accuracy,\n",
    "            AVG(f1_score) as avg_f1_score\n",
    "        FROM ml_experiments\n",
    "        GROUP BY dataset, model_type\n",
    "    ) TO '{parquet_path}' (FORMAT PARQUET)\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Exported results to: {parquet_path}\")\n",
    "\n",
    "# Read Parquet file\n",
    "parquet_data = con.execute(f\"SELECT * FROM '{parquet_path}'\").df()\n",
    "print(\"\\nData from Parquet file:\")\n",
    "parquet_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Time-based Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze experiments by month\n",
    "monthly_stats = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        DATE_TRUNC('month', timestamp) as month,\n",
    "        COUNT(*) as experiments,\n",
    "        ROUND(AVG(accuracy), 4) as avg_accuracy,\n",
    "        ROUND(AVG(training_time), 2) as avg_training_time\n",
    "    FROM ml_experiments\n",
    "    GROUP BY month\n",
    "    ORDER BY month DESC\n",
    "    LIMIT 12\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Monthly experiment statistics:\")\n",
    "monthly_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance: DuckDB vs Pandas\n",
    "\n",
    "Let's compare query performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create larger dataset for benchmarking\n",
    "n_large = 100000\n",
    "df_large = pd.DataFrame({\n",
    "    'id': range(n_large),\n",
    "    'category': np.random.choice(['A', 'B', 'C', 'D', 'E'], n_large),\n",
    "    'value': np.random.randn(n_large),\n",
    "    'amount': np.random.uniform(0, 1000, n_large)\n",
    "})\n",
    "\n",
    "# Pandas aggregation\n",
    "start = time.time()\n",
    "pandas_result = df_large.groupby('category').agg({\n",
    "    'value': ['mean', 'std', 'min', 'max'],\n",
    "    'amount': 'sum'\n",
    "})\n",
    "pandas_time = time.time() - start\n",
    "\n",
    "# DuckDB aggregation\n",
    "start = time.time()\n",
    "duckdb_result = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        category,\n",
    "        AVG(value) as mean_value,\n",
    "        STDDEV(value) as std_value,\n",
    "        MIN(value) as min_value,\n",
    "        MAX(value) as max_value,\n",
    "        SUM(amount) as sum_amount\n",
    "    FROM df_large\n",
    "    GROUP BY category\n",
    "\"\"\").df()\n",
    "duckdb_time = time.time() - start\n",
    "\n",
    "print(f\"Pandas time: {pandas_time:.4f} seconds\")\n",
    "print(f\"DuckDB time: {duckdb_time:.4f} seconds\")\n",
    "print(f\"Speedup: {pandas_time / duckdb_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Connecting DuckDB to PostgreSQL\n",
    "\n",
    "DuckDB can read data from PostgreSQL tables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install postgres extension for DuckDB\n",
    "con.execute(\"INSTALL postgres\")\n",
    "con.execute(\"LOAD postgres\")\n",
    "\n",
    "# Connect to PostgreSQL (adjust connection string as needed)\n",
    "postgres_conn = \"postgresql://mluser:mlpassword@postgres:5432/ml_practice\"\n",
    "\n",
    "try:\n",
    "    # Attach PostgreSQL database\n",
    "    con.execute(f\"ATTACH '{postgres_conn}' AS pg (TYPE POSTGRES)\")\n",
    "    \n",
    "    # List PostgreSQL tables\n",
    "    pg_tables = con.execute(\"SHOW TABLES FROM pg.ml_experiments\").df()\n",
    "    print(\"PostgreSQL tables:\")\n",
    "    print(pg_tables)\n",
    "    \n",
    "    # Query PostgreSQL data\n",
    "    pg_data = con.execute(\"SELECT * FROM pg.ml_experiments.experiments LIMIT 5\").df()\n",
    "    print(\"\\nData from PostgreSQL:\")\n",
    "    print(pg_data)\n",
    "except Exception as e:\n",
    "    print(f\"Note: PostgreSQL connection requires data in PostgreSQL. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cleanup and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all tables\n",
    "print(\"All tables in DuckDB:\")\n",
    "con.execute(\"SHOW TABLES\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table info\n",
    "print(\"\\nTable schema:\")\n",
    "con.execute(\"DESCRIBE ml_experiments\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection (good practice)\n",
    "con.close()\n",
    "print(\"DuckDB connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned:\n",
    "\n",
    "1. ✅ How to create DuckDB connections (in-memory and file-based)\n",
    "2. ✅ Query Pandas DataFrames directly with SQL\n",
    "3. ✅ Create persistent tables\n",
    "4. ✅ Use advanced SQL features (window functions, CTEs, aggregations)\n",
    "5. ✅ Work with CSV and Parquet files\n",
    "6. ✅ Perform time-based analysis\n",
    "7. ✅ Compare performance with Pandas\n",
    "8. ✅ Connect to PostgreSQL\n",
    "\n",
    "### When to use DuckDB:\n",
    "- ✅ Analytical queries on medium-to-large datasets (10K - 100M+ rows)\n",
    "- ✅ Complex SQL queries with joins, window functions, CTEs\n",
    "- ✅ Reading CSV/Parquet files without loading into memory\n",
    "- ✅ Faster aggregations compared to Pandas\n",
    "- ✅ Working with data that doesn't fit in memory (out-of-core processing)\n",
    "\n",
    "### When to use Pandas:\n",
    "- ✅ Small datasets (< 10K rows)\n",
    "- ✅ Complex data transformations with Python logic\n",
    "- ✅ Integration with ML libraries (scikit-learn, PyTorch, etc.)\n",
    "- ✅ Time series operations with specific Pandas features\n",
    "\n",
    "### Next Steps:\n",
    "1. Try DuckDB with your own ML experiment data\n",
    "2. Explore the [DuckDB documentation](https://duckdb.org/docs/)\n",
    "3. Combine DuckDB with ML workflows for faster data preprocessing\n",
    "4. Use DuckDB for feature engineering in your ML pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
